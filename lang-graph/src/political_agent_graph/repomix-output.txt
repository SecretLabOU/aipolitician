This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
__init__.py
graph.py
mock_db.py
prompts.py
state.py

================================================================
Files
================================================================

================
File: __init__.py
================
"""Political agent graph package.

This package implements a LangGraph for processing political queries through
sentiment analysis, context extraction, database queries, and response generation.
"""

from political_agent_graph.graph import graph as political_agent_graph

__all__ = ["political_agent_graph"]

================
File: graph.py
================
"""Main implementation of the political agent graph.

This module implements the flowchart as a LangGraph, defining the nodes and edges
that process user input through sentiment analysis, context extraction, database queries,
and response generation.
"""

from typing import List, Literal, TypedDict, cast

from langchain_core.messages import BaseMessage
from langchain_core.runnables import RunnableConfig
from langgraph.graph import END, START, StateGraph

from political_agent_graph.mock_db import DB_REGISTRY
from political_agent_graph.prompts import (
    CONTEXT_PROMPT,
    DEFLECTION_PROMPT,
    FACT_CHECK_PROMPT,
    FINAL_OUTPUT_PROMPT,
    RESPONSE_PROMPT,
    ROUTING_PROMPT,
    SENTIMENT_PROMPT,
    TONE_PROMPT,
)
from political_agent_graph.state import AgentState, InputState
from shared.utils import load_chat_model


async def analyze_sentiment(state: AgentState, config: RunnableConfig) -> dict[str, str]:
    """Analyze sentiment of user input."""
    model = load_chat_model("anthropic/claude-3-haiku-20240307")
    messages = [
        {"role": "system", "content": SENTIMENT_PROMPT},
        {"role": "human", "content": state.messages[-1].content},
    ]
    response = await model.ainvoke(messages)
    return {"sentiment": response.content}


async def extract_context(state: AgentState, config: RunnableConfig) -> dict[str, str]:
    """Extract context from user input."""
    model = load_chat_model("anthropic/claude-3-haiku-20240307")
    messages = [
        {"role": "system", "content": CONTEXT_PROMPT},
        {"role": "human", "content": state.messages[-1].content},
    ]
    response = await model.ainvoke(messages)
    return {"context": response.content}


class RouterResponse(TypedDict):
    """Response format for the router."""
    selected_databases: List[str]


async def route_by_context(state: AgentState, config: RunnableConfig) -> dict[str, list[str]]:
    """Route to appropriate databases based on context."""
    model = load_chat_model("anthropic/claude-3-haiku-20240307")
    model = model.with_structured_output(RouterResponse)
    messages = [
        {"role": "system", "content": ROUTING_PROMPT},
        {"role": "human", "content": state.context},
    ]
    response = cast(RouterResponse, await model.ainvoke(messages))
    return {"selected_databases": response["selected_databases"]}


async def query_databases(state: AgentState, config: RunnableConfig) -> dict[str, str]:
    """Query selected databases and aggregate results."""
    results = {}
    aggregated = []
    
    for db in state.selected_databases:
        if db == "voting":
            results["voting_data"] = DB_REGISTRY["voting"](state.context)
            aggregated.append(results["voting_data"])
        elif db == "bio":
            results["bio_data"] = DB_REGISTRY["bio"](state.context)
            aggregated.append(results["bio_data"])
        elif db == "social":
            results["social_data"] = DB_REGISTRY["social"](state.context)
            aggregated.append(results["social_data"])
        elif db == "policy":
            results["policy_data"] = DB_REGISTRY["policy"](state.context)
            aggregated.append(results["policy_data"])
    
    results["aggregated_data"] = " | ".join(aggregated)
    return results


def check_data_found(state: AgentState) -> Literal["generate_tone", "generate_deflection"]:
    """Check if data was found and route accordingly."""
    return "generate_tone" if state.aggregated_data.strip() else "generate_deflection"


async def generate_tone(state: AgentState, config: RunnableConfig) -> dict[str, str]:
    """Generate appropriate tone for response."""
    # Get persona style
    persona_style = DB_REGISTRY["persona"]("")
    
    model = load_chat_model("anthropic/claude-3-haiku-20240307")
    messages = [
        {"role": "system", "content": TONE_PROMPT},
        {"role": "human", "content": f"Sentiment: {state.sentiment}\nData: {state.aggregated_data}\nPersona: {persona_style}"},
    ]
    response = await model.ainvoke(messages)
    return {"tone": response.content, "persona_style": persona_style}


async def generate_deflection(state: AgentState, config: RunnableConfig) -> dict[str, str]:
    """Generate appropriate deflection."""
    # Get persona style
    persona_style = DB_REGISTRY["persona"]("")
    
    model = load_chat_model("anthropic/claude-3-haiku-20240307")
    messages = [
        {"role": "system", "content": DEFLECTION_PROMPT},
        {"role": "human", "content": f"Sentiment: {state.sentiment}\nContext: {state.context}\nPersona: {persona_style}"},
    ]
    response = await model.ainvoke(messages)
    return {"deflection": response.content, "persona_style": persona_style}


async def compose_response(state: AgentState, config: RunnableConfig) -> dict[str, str]:
    """Compose draft response."""
    # Get chat history
    chat_history = DB_REGISTRY["chat_memory"]("")
    
    model = load_chat_model("anthropic/claude-3-haiku-20240307")
    content = f"""Tone: {state.tone}
Data/Deflection: {state.aggregated_data or state.deflection}
Chat History: {chat_history}"""
    
    messages = [
        {"role": "system", "content": RESPONSE_PROMPT},
        {"role": "human", "content": content},
    ]
    response = await model.ainvoke(messages)
    return {"draft_response": response.content}


async def fact_check(state: AgentState, config: RunnableConfig) -> dict[str, str]:
    """Fact check the draft response."""
    # Get factual knowledge
    facts = DB_REGISTRY["factual_kb"]("")
    
    model = load_chat_model("anthropic/claude-3-haiku-20240307")
    messages = [
        {"role": "system", "content": FACT_CHECK_PROMPT},
        {"role": "human", "content": f"Response: {state.draft_response}\nFacts: {facts}\nData: {state.aggregated_data}"},
    ]
    response = await model.ainvoke(messages)
    return {"verified_response": response.content}


async def generate_final_output(
    state: AgentState, config: RunnableConfig
) -> dict[str, list[BaseMessage]]:
    """Generate final output."""
    model = load_chat_model("anthropic/claude-3-haiku-20240307")
    messages = [
        {"role": "system", "content": FINAL_OUTPUT_PROMPT},
        {
            "role": "human",
            "content": f"""Tone: {state.tone}
Persona: {state.persona_style}
Verified Response: {state.verified_response}""",
        },
    ]
    response = await model.ainvoke(messages)
    return {"messages": [response]}


# Define the graph
builder = StateGraph(AgentState, input=InputState)

# Add nodes
builder.add_node("analyze_sentiment", analyze_sentiment)
builder.add_node("extract_context", extract_context)
builder.add_node("route_by_context", route_by_context)
builder.add_node("query_databases", query_databases)
builder.add_node("generate_tone", generate_tone)
builder.add_node("generate_deflection", generate_deflection)
builder.add_node("compose_response", compose_response)
builder.add_node("fact_check", fact_check)
builder.add_node("generate_final_output", generate_final_output)

# Add edges
builder.add_edge(START, ["analyze_sentiment", "extract_context"])
builder.add_edge("extract_context", "route_by_context")
builder.add_edge("route_by_context", "query_databases")
builder.add_edge("query_databases", check_data_found)
builder.add_edge("analyze_sentiment", ["generate_tone", "generate_deflection"])
builder.add_edge("generate_tone", "compose_response")
builder.add_edge("generate_deflection", "compose_response")
builder.add_edge("compose_response", "fact_check")
builder.add_edge("fact_check", "generate_final_output")
builder.add_edge("generate_final_output", END)

# Compile the graph
graph = builder.compile()
graph.name = "PoliticalAgentGraph"

================
File: mock_db.py
================
"""Mock database implementations for the political agent graph.

This module provides mock implementations of the various databases used in the graph.
Each function simulates a database query and returns predefined data.
"""

def query_voting_db(query: str) -> str:
    """Mock implementation of voting database."""
    return "Mock voting record data: Voted yes on Bill 123, no on Bill 456"

def query_bio_db(query: str) -> str:
    """Mock implementation of biography database."""
    return "Mock biography data: Born in Springfield, graduated from State University"

def query_social_db(query: str) -> str:
    """Mock implementation of social media database."""
    return "Mock social media data: Recent tweets about climate change and education"

def query_policy_db(query: str) -> str:
    """Mock implementation of policy database."""
    return "Mock policy data: Supports renewable energy and education reform"

def query_persona_db(query: str) -> str:
    """Mock implementation of persona database."""
    return "Mock persona data: Professional and diplomatic communication style"

def query_chat_memory_db(query: str) -> str:
    """Mock implementation of chat memory database."""
    return "Mock chat history: Previously discussed education policy"

def query_factual_kb(query: str) -> str:
    """Mock implementation of factual knowledge base."""
    return "Mock fact check: Statement verified against public records"

# Dictionary mapping database names to their query functions
DB_REGISTRY = {
    "voting": query_voting_db,
    "bio": query_bio_db,
    "social": query_social_db,
    "policy": query_policy_db,
    "persona": query_persona_db,
    "chat_memory": query_chat_memory_db,
    "factual_kb": query_factual_kb,
}

================
File: prompts.py
================
"""System prompts for the political agent graph.

This module defines the system prompts used by the various agents in the graph.
Each prompt is designed to guide the agent in performing its specific task.
"""

SENTIMENT_PROMPT = """Analyze the sentiment of the user's input.
Focus on emotional tone, attitude, and underlying feelings.
Return a brief description of the sentiment."""

CONTEXT_PROMPT = """Extract the main context and topic from the user's input.
Focus on identifying key subjects, themes, and information needs.
Return a brief description of the context."""

ROUTING_PROMPT = """Based on the extracted context, determine which databases should be queried.
Available databases: voting, bio, social, policy
Return a list of relevant database names."""

TONE_PROMPT = """Generate an appropriate tone for the response based on:
1. The user's sentiment
2. The aggregated data
3. The persona style

Return a brief description of the appropriate tone to use."""

DEFLECTION_PROMPT = """Generate an appropriate deflection based on:
1. The user's sentiment
2. The extracted context
3. The persona style

Return a diplomatic deflection that acknowledges the query without providing specifics."""

RESPONSE_PROMPT = """Compose a response using:
1. The determined tone
2. The aggregated data or deflection
3. The chat history context

Generate a natural, contextually appropriate response."""

FACT_CHECK_PROMPT = """Verify the accuracy of the draft response against:
1. The factual knowledge base
2. The aggregated data

Ensure all statements are supported by the available data."""

FINAL_OUTPUT_PROMPT = """Generate the final response ensuring:
1. It maintains the appropriate tone
2. It incorporates fact-checked information
3. It follows the persona style
4. It is contextually appropriate

Create a clear, concise, and well-structured response."""

================
File: state.py
================
"""State management for the political agent graph.

This module defines the state structures used in the political agent graph.
"""

from dataclasses import dataclass, field
from typing import Annotated, List

from langchain_core.messages import AnyMessage
from langgraph.graph import add_messages


@dataclass(kw_only=True)
class InputState:
    """Input state for the agent."""
    messages: Annotated[list[AnyMessage], add_messages]


@dataclass(kw_only=True)
class AgentState(InputState):
    """State for the political agent graph."""
    # User input processing
    sentiment: str = ""
    context: str = ""
    
    # Routing and database selection
    selected_databases: list[str] = field(default_factory=list)
    
    # Database results
    voting_data: str = ""
    bio_data: str = ""
    social_data: str = ""
    policy_data: str = ""
    aggregated_data: str = ""
    
    # Response generation
    data_found: bool = True
    tone: str = ""
    persona_style: str = ""
    deflection: str = ""
    draft_response: str = ""
    verified_response: str = ""
    
    # Chat memory
    chat_memory: list[str] = field(default_factory=list)



================================================================
End of Codebase
================================================================
