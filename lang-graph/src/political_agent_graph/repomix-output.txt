This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
__init__.py
graph.py
mock_db.py
prompts.py
state.py

================================================================
Files
================================================================

================
File: __init__.py
================
"""Political agent graph package.

This package implements a LangGraph for processing political queries through
sentiment analysis, context extraction, database queries, and response generation.
"""

from political_agent_graph.graph import graph

__all__ = ["graph"]

================
File: graph.py
================
"""Main implementation of the political agent graph.

This module implements the flowchart as a LangGraph, defining the nodes and edges
that process user input through sentiment analysis, context extraction, database queries,
and response generation.

The graph follows this flow:
1. User input is processed in parallel by Sentiment and Context agents
2. Context is used by the Routing agent to select appropriate databases
3. Selected databases (Voting, Bio, Social, Policy) are queried
4. Based on whether data is found:
   - If data is found: Generate appropriate tone using Persona DB
   - If no data is found: Generate a deflection
5. Response is composed using tone/deflection and Chat Memory
6. Draft response is fact-checked against Factual Knowledge Base
7. Final output is generated and returned to the user
"""

from typing import List, Literal, TypedDict, cast

from langchain_core.messages import BaseMessage
from langchain_core.runnables import RunnableConfig
from langgraph.graph import END, START, StateGraph

from political_agent_graph.mock_db import DB_REGISTRY
from political_agent_graph.prompts import (
    CONTEXT_PROMPT,
    DEFLECTION_PROMPT,
    FACT_CHECK_PROMPT,
    FINAL_OUTPUT_PROMPT,
    RESPONSE_PROMPT,
    ROUTING_PROMPT,
    SENTIMENT_PROMPT,
    TONE_PROMPT,
)
from political_agent_graph.state import AgentState, InputState
from shared.utils import load_chat_model


async def analyze_sentiment(state: AgentState, config: RunnableConfig) -> dict[str, str]:
    """Analyze sentiment of user input.
    
    This implements the "Sentiment Agent" node in the flowchart,
    which processes the user input to determine sentiment.
    """
    model = load_chat_model("anthropic/claude-3-haiku-20240307")
    messages = [
        {"role": "system", "content": SENTIMENT_PROMPT},
        {"role": "human", "content": state.messages[-1].content},
    ]
    response = await model.ainvoke(messages)
    return {"sentiment": response.content}


async def extract_context(state: AgentState, config: RunnableConfig) -> dict[str, str]:
    """Extract context from user input.
    
    This implements the "Context Agent" node in the flowchart,
    which processes the user input to extract relevant context.
    """
    model = load_chat_model("anthropic/claude-3-haiku-20240307")
    messages = [
        {"role": "system", "content": CONTEXT_PROMPT},
        {"role": "human", "content": state.messages[-1].content},
    ]
    response = await model.ainvoke(messages)
    return {"context": response.content}


class RouterResponse(TypedDict):
    """Response format for the router."""
    selected_databases: List[str]


async def route_by_context(state: AgentState, config: RunnableConfig) -> dict[str, list[str]]:
    """Route to appropriate databases based on context.
    
    This implements the "Select Database(s)?" decision point in the flowchart.
    The function determines which databases (Voting, Bio, Social, Policy)
    should be queried based on the extracted context.
    """
    model = load_chat_model("anthropic/claude-3-haiku-20240307")
    model = model.with_structured_output(RouterResponse)
    messages = [
        {"role": "system", "content": ROUTING_PROMPT},
        {"role": "human", "content": state.context},
    ]
    response = cast(RouterResponse, await model.ainvoke(messages))
    return {"selected_databases": response["selected_databases"]}


async def query_databases(state: AgentState, config: RunnableConfig) -> dict[str, str]:
    """Query selected databases and aggregate results.
    
    This implements the database query flows in the flowchart,
    where each selected database (Voting DB, Bio DB, Social DB, Policy DB)
    is queried individually based on the routing decision.
    """
    results = {}
    aggregated = []
    
    # Query each selected database individually
    for db in state.selected_databases:
        if db == "voting":
            # Query Voting DB
            results["voting_data"] = DB_REGISTRY["voting"](state.context)
            aggregated.append(results["voting_data"])
        elif db == "bio":
            # Query Bio DB
            results["bio_data"] = DB_REGISTRY["bio"](state.context)
            aggregated.append(results["bio_data"])
        elif db == "social":
            # Query Social DB
            results["social_data"] = DB_REGISTRY["social"](state.context)
            aggregated.append(results["social_data"])
        elif db == "policy":
            # Query Policy DB
            results["policy_data"] = DB_REGISTRY["policy"](state.context)
            aggregated.append(results["policy_data"])
    
    # Aggregate the results from all queried databases
    results["aggregated_data"] = " | ".join(aggregated)
    return results


def check_data_found(state: AgentState) -> Literal["generate_tone", "generate_deflection"]:
    """Check if data was found and route accordingly.
    
    This is the "Is Data Found?" decision point in the flowchart.
    If data is found, route to tone generation.
    If no data is found, route to deflection generation.
    """
    # Check if aggregated data exists and is not empty
    if state.aggregated_data.strip():
        return "generate_tone"  # Yes, data found
    else:
        return "generate_deflection"  # No data found


async def generate_tone(state: AgentState, config: RunnableConfig) -> dict[str, str]:
    """Generate appropriate tone for response.
    
    This implements the "Tone Agent" node in the flowchart,
    which checks the Persona DB to determine the appropriate tone.
    """
    # Get persona style from Persona DB
    persona_style = DB_REGISTRY["persona"]("")
    
    model = load_chat_model("anthropic/claude-3-haiku-20240307")
    messages = [
        {"role": "system", "content": TONE_PROMPT},
        {"role": "human", "content": f"Sentiment: {state.sentiment}\nData: {state.aggregated_data}\nPersona: {persona_style}"},
    ]
    response = await model.ainvoke(messages)
    return {"tone": response.content, "persona_style": persona_style}


async def generate_deflection(state: AgentState, config: RunnableConfig) -> dict[str, str]:
    """Generate appropriate deflection.
    
    This implements the "Deflection Agent" node in the flowchart,
    which generates a diplomatic deflection when no relevant data is found.
    """
    # Get persona style from Persona DB
    persona_style = DB_REGISTRY["persona"]("")
    
    model = load_chat_model("anthropic/claude-3-haiku-20240307")
    messages = [
        {"role": "system", "content": DEFLECTION_PROMPT},
        {"role": "human", "content": f"Sentiment: {state.sentiment}\nContext: {state.context}\nPersona: {persona_style}"},
    ]
    response = await model.ainvoke(messages)
    return {"deflection": response.content, "persona_style": persona_style}


async def compose_response(state: AgentState, config: RunnableConfig) -> dict[str, str]:
    """Compose draft response.
    
    This implements the "Response Composer" node in the flowchart,
    which consults the Chat Memory DB to incorporate conversation history.
    """
    # Get chat history from Chat Memory DB
    chat_history = DB_REGISTRY["chat_memory"]("")
    
    model = load_chat_model("anthropic/claude-3-haiku-20240307")
    content = f"""Tone: {state.tone}
Data/Deflection: {state.aggregated_data or state.deflection}
Chat History: {chat_history}"""
    
    messages = [
        {"role": "system", "content": RESPONSE_PROMPT},
        {"role": "human", "content": content},
    ]
    response = await model.ainvoke(messages)
    return {"draft_response": response.content}


async def fact_check(state: AgentState, config: RunnableConfig) -> dict[str, str]:
    """Fact check the draft response.
    
    This implements the "Fact Checking Agent" node in the flowchart,
    which verifies the draft response against the Factual Knowledge Base.
    """
    # Get factual knowledge from the knowledge base
    facts = DB_REGISTRY["factual_kb"]("")
    
    # Verify the draft response against the factual knowledge base
    model = load_chat_model("anthropic/claude-3-haiku-20240307")
    messages = [
        {"role": "system", "content": FACT_CHECK_PROMPT},
        {"role": "human", "content": f"Response: {state.draft_response}\nFacts: {facts}\nData: {state.aggregated_data}"},
    ]
    response = await model.ainvoke(messages)
    return {"verified_response": response.content}


async def generate_final_output(
    state: AgentState, config: RunnableConfig
) -> dict[str, list[BaseMessage]]:
    """Generate final output.
    
    This implements the "Final Output" node in the flowchart,
    which produces the final response to the user.
    """
    model = load_chat_model("anthropic/claude-3-haiku-20240307")
    messages = [
        {"role": "system", "content": FINAL_OUTPUT_PROMPT},
        {
            "role": "human",
            "content": f"""Tone: {state.tone}
Persona: {state.persona_style}
Verified Response: {state.verified_response}""",
        },
    ]
    response = await model.ainvoke(messages)
    return {"messages": [response]}


# Define the graph
builder = StateGraph(AgentState, input=InputState)

# Add nodes corresponding to the flowchart
builder.add_node("analyze_sentiment", analyze_sentiment)  # Sentiment Agent
builder.add_node("extract_context", extract_context)      # Context Agent
builder.add_node("route_by_context", route_by_context)    # Routing Agent
builder.add_node("query_databases", query_databases)      # Database Queries
builder.add_node("generate_tone", generate_tone)          # Tone Agent
builder.add_node("generate_deflection", generate_deflection)  # Deflection Agent
builder.add_node("compose_response", compose_response)    # Response Composer
builder.add_node("fact_check", fact_check)                # Fact Checking Agent
builder.add_node("generate_final_output", generate_final_output)  # Final Output

# Add edges to match the flowchart flow
# 1. Parallel flow: User Input -> Sentiment & Context
builder.add_edge(START, "analyze_sentiment")
builder.add_edge(START, "extract_context")

# 2. Context -> Routing -> Database Queries
builder.add_edge("extract_context", "route_by_context")
builder.add_edge("route_by_context", "query_databases")

# 3. Data Found Decision Point
builder.add_conditional_edges("query_databases", check_data_found)

# 4. Sentiment flows to both Tone and Deflection
builder.add_edge("analyze_sentiment", "generate_tone")
builder.add_edge("analyze_sentiment", "generate_deflection")

# 5. Tone/Deflection -> Response Composer
builder.add_edge("generate_tone", "compose_response")
builder.add_edge("generate_deflection", "compose_response")

# 6. Response Composer -> Fact Check -> Final Output
builder.add_edge("compose_response", "fact_check")
builder.add_edge("fact_check", "generate_final_output")
builder.add_edge("generate_final_output", END)

# Compile the graph
graph = builder.compile()
graph.name = "PoliticalAgentGraph"

================
File: mock_db.py
================
"""Mock database implementations for the political agent graph.

This module provides mock implementations of the various databases used in the graph.
Each function simulates a database query and returns predefined data.
"""

def query_voting_db(query: str) -> str:
    """Mock implementation of voting database."""
    return "Mock voting record data: Voted yes on Bill 123, no on Bill 456"

def query_bio_db(query: str) -> str:
    """Mock implementation of biography database."""
    return "Mock biography data: Born in Springfield, graduated from State University"

def query_social_db(query: str) -> str:
    """Mock implementation of social media database."""
    return "Mock social media data: Recent tweets about climate change and education"

def query_policy_db(query: str) -> str:
    """Mock implementation of policy database."""
    return "Mock policy data: Supports renewable energy and education reform"

def query_persona_db(query: str) -> str:
    """Mock implementation of persona database."""
    return "Mock persona data: Professional and diplomatic communication style"

def query_chat_memory_db(query: str) -> str:
    """Mock implementation of chat memory database."""
    return "Mock chat history: Previously discussed education policy"

def query_factual_kb(query: str) -> str:
    """Mock implementation of factual knowledge base."""
    return "Mock fact check: Statement verified against public records"

# Dictionary mapping database names to their query functions
DB_REGISTRY = {
    "voting": query_voting_db,
    "bio": query_bio_db,
    "social": query_social_db,
    "policy": query_policy_db,
    "persona": query_persona_db,
    "chat_memory": query_chat_memory_db,
    "factual_kb": query_factual_kb,
}

================
File: prompts.py
================
"""System prompts for the political agent graph.

This module defines the system prompts used by the various agents in the graph.
Each prompt is designed to guide the agent in performing its specific task.
"""

SENTIMENT_PROMPT = """Analyze the sentiment of the user's input.
Focus on emotional tone, attitude, and underlying feelings.
Return a brief description of the sentiment."""

CONTEXT_PROMPT = """Extract the main context and topic from the user's input.
Focus on identifying key subjects, themes, and information needs.
Return a brief description of the context."""

ROUTING_PROMPT = """Based on the extracted context, determine which databases should be queried.
Available databases: voting, bio, social, policy
Return a list of relevant database names."""

TONE_PROMPT = """Generate an appropriate tone for the response based on:
1. The user's sentiment
2. The aggregated data
3. The persona style

Return a brief description of the appropriate tone to use."""

DEFLECTION_PROMPT = """Generate an appropriate deflection based on:
1. The user's sentiment
2. The extracted context
3. The persona style

Return a diplomatic deflection that acknowledges the query without providing specifics."""

RESPONSE_PROMPT = """Compose a response using:
1. The determined tone
2. The aggregated data or deflection
3. The chat history context

Generate a natural, contextually appropriate response."""

FACT_CHECK_PROMPT = """Verify the accuracy of the draft response against:
1. The factual knowledge base
2. The aggregated data

Ensure all statements are supported by the available data."""

FINAL_OUTPUT_PROMPT = """Generate the final response ensuring:
1. It maintains the appropriate tone
2. It incorporates fact-checked information
3. It follows the persona style
4. It is contextually appropriate

Create a clear, concise, and well-structured response."""

================
File: state.py
================
"""State management for the political agent graph.

This module defines the state structures used in the political agent graph.
"""

from dataclasses import dataclass, field
from typing import Annotated, List

from langchain_core.messages import AnyMessage
from langgraph.graph import add_messages


@dataclass(kw_only=True)
class InputState:
    """Input state for the agent."""
    messages: Annotated[list[AnyMessage], add_messages]


@dataclass(kw_only=True)
class AgentState(InputState):
    """State for the political agent graph."""
    # User input processing
    sentiment: str = ""
    context: str = ""
    
    # Routing and database selection
    selected_databases: list[str] = field(default_factory=list)
    
    # Database results
    voting_data: str = ""
    bio_data: str = ""
    social_data: str = ""
    policy_data: str = ""
    aggregated_data: str = ""
    
    # Response generation
    data_found: bool = True
    tone: str = ""
    persona_style: str = ""
    deflection: str = ""
    draft_response: str = ""
    verified_response: str = ""
    
    # Chat memory
    chat_memory: list[str] = field(default_factory=list)



================================================================
End of Codebase
================================================================
